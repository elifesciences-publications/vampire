{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example of a VAE for BCR sequences made using a bi-directional LSTM.\n",
    "LSTMs are extremely slow to train.\n",
    "Performance (based on out of sample cross-entropy) of this LSTM based implementation is inferior to a standard dense layer network so therefore this is just to provide an example of how to make such an architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic imports\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import math, random, re\n",
    "import time\n",
    "import pickle\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Machine learning/Stats imports \n",
    "from scipy.stats import norm\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Bidirectional, RepeatVector, Reshape\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "from keras.layers import Input, Dense, Lambda, Dropout,Activation, TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amino acid alphabet:\n",
    "AA_ORDER = 'ACDEFGHIKLMNPQRSTVWY-'\n",
    "AA_LIST = list(AA_ORDER)\n",
    "AA_DICT = {c:i for i, c in enumerate(AA_LIST)}\n",
    "AA_DICT_REV = {i:c for i, c in enumerate(AA_LIST)}\n",
    "AA_SET = set(AA_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_seq(seq):\n",
    "    '''Filter away ambiguous character containing sequences.'''\n",
    "    if set(list(seq)) <= AA_SET:\n",
    "        return(seq)\n",
    "    else:\n",
    "        return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2onehot(seq_list):\n",
    "    '''\n",
    "    Translate a list of amino acid sequences into a 3D tensor with onehot encodings.\n",
    "    NB. all sequences must be of equal length.\n",
    "    '''\n",
    "    seqlen = len(seq_list[0])\n",
    "    assert(not [True for s in seq_list if len(s) != seqlen])\n",
    "    onehot_tensor = np.zeros((len(seq_list), seqlen, len(AA_SET)))\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        for j, a in enumerate(seq):\n",
    "            onehot_tensor[i][j][AA_DICT[a]] = 1\n",
    "    return(onehot_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot2seq(onehot_tensor):\n",
    "    '''\n",
    "    Translate a 3D tensor with onehot encodings to a list of amino acid sequences.\n",
    "    '''\n",
    "    seq_list = list()\n",
    "    for i in range(onehot_tensor.shape[0]):\n",
    "        seq = list()\n",
    "        for j in range(onehot_tensor.shape[1]):\n",
    "            seq.append(AA_DICT_REV[onehot_tensor[i][j].argmax()])\n",
    "        seq_list.append(''.join(seq))\n",
    "    return(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data has 10000 sequences.\n"
     ]
    }
   ],
   "source": [
    "# Read in some sequences:\n",
    "MAX_SEQS = 10000\n",
    "fnam = 'BCR_data/spurf_heavy_chain_AHo.fasta'\n",
    "seq_list = list()\n",
    "for i, record in enumerate(SeqIO.parse(fnam, 'fasta')):\n",
    "    if i >= MAX_SEQS:\n",
    "        break\n",
    "    seq_list.append(str(record.seq))\n",
    "print('Input data has {} sequences.'.format(len(seq_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onehot encoded tensor has this shape: (10000, 149, 21)\n"
     ]
    }
   ],
   "source": [
    "# Transform to onehot:\n",
    "onehot_tensor = seq2onehot(seq_list)\n",
    "print('Onehot encoded tensor has this shape: {}'.format(onehot_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various network definitions:\n",
    "batch_size = 100\n",
    "input_shape = onehot_tensor.shape[1:]\n",
    "input_total_dim = np.array(input_shape).prod()\n",
    "\n",
    "latent_dim = 10\n",
    "lstm_nodes = 149\n",
    "#lstm_nodes = 30\n",
    "\n",
    "epsilon_std = 1.0\n",
    "def sampling(args):\n",
    "    '''This function draws a sample from the multinomial defined by the latent variables.'''\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.0, stddev=epsilon_std)\n",
    "    return(z_mean + K.exp(z_log_var / 2) * epsilon)\n",
    "\n",
    "def vae_loss(io_encoder, io_decoder):\n",
    "    '''The loss function is the sum of the cross-entropy and KL divergence.'''\n",
    "    # Notice that \"objectives.categorical_crossentropy(io_encoder, io_decoder)\" is a vector so it is averaged:\n",
    "    xent_loss = input_total_dim * K.mean(objectives.categorical_crossentropy(io_encoder, io_decoder))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return(xent_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 149, 21)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 149, 298)          203832    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 298)               534016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2990      \n",
      "=================================================================\n",
      "Total params: 740,838\n",
      "Trainable params: 740,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoding layers:\n",
    "io_encoder = Input(shape=input_shape)\n",
    "lstm_encoder1 = Bidirectional(LSTM(lstm_nodes, return_sequences=True, recurrent_dropout=0.2), merge_mode='concat')(io_encoder)\n",
    "lstm_encoder2 = Bidirectional(LSTM(lstm_nodes, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')(lstm_encoder1)\n",
    "\n",
    "\n",
    "# Latent layers:\n",
    "z_mean = Dense(latent_dim)(lstm_encoder2)\n",
    "z_log_var = Dense(latent_dim)(lstm_encoder2)\n",
    "z = Lambda(sampling, output_shape=(latent_dim, ))([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(io_encoder, z_mean)\n",
    "encoder.summary()\n",
    "#SVG(model_to_dot(encoder, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 149, 10)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 149, 298)          190720    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 298)               534016    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3129)              935571    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 149, 21)           0         \n",
      "=================================================================\n",
      "Total params: 1,660,307\n",
      "Trainable params: 1,660,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoding layers:\n",
    "rep_decoder = RepeatVector(input_shape[0])\n",
    "lstm_decoder1 = Bidirectional(LSTM(lstm_nodes, return_sequences=True, recurrent_dropout=0.2), merge_mode='concat')\n",
    "lstm_decoder2 = Bidirectional(LSTM(lstm_nodes, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')\n",
    "decoder_out = Dense(input_total_dim, activation='sigmoid')\n",
    "reshape2input = Reshape(input_shape)#, input_shape=(None, decoder_architecture[1]))\n",
    "io_decoder = reshape2input(decoder_out(lstm_decoder2(lstm_decoder1(rep_decoder(z)))))\n",
    "\n",
    "\n",
    "io_z = Input(shape=(latent_dim,))\n",
    "io_decoder_means = reshape2input(decoder_out(lstm_decoder2(lstm_decoder1(rep_decoder(io_z)))))\n",
    "decoder = Model(io_z, io_decoder_means)\n",
    "decoder.summary()\n",
    "#SVG(model_to_dot(decoder, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 149, 21)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 149, 298)      203832      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 298)           534016      bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            2990        bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            2990        bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 10)            0           dense_1[0][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)   (None, 149, 10)       0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional)  (None, 149, 298)      190720      repeat_vector_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional)  (None, 298)           534016      bidirectional_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 3129)          935571      bidirectional_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 149, 21)       0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2,404,135\n",
      "Trainable params: 2,404,135\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae = Model(io_encoder, io_decoder)\n",
    "vae.compile(optimizer=\"adam\", loss=vae_loss)\n",
    "vae.summary()\n",
    "#SVG(model_to_dot(vae, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/test:\n",
    "x_train, x_test = train_test_split(onehot_tensor, test_size=0.1, shuffle=True)\n",
    "sl = len(x_train) // (batch_size*10)\n",
    "x_train = x_train[:(sl*batch_size*10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/2\n",
      "8100/8100 [==============================] - 487s - loss: 5342.1308 - val_loss: 2788.3977\n",
      "Epoch 2/2\n",
      " 300/8100 [>.............................] - ETA: 474s - loss: 2719.9393"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-afb4dc73eb1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                   callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/easybuild/software/Python/3.6.3-foss-2016b-fh1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 2\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "vae_log = vae.fit(x_train,\n",
    "                  x_train,  # VAE is unsupervised so y=X\n",
    "                  shuffle=True,\n",
    "                  epochs=nb_epoch,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_split=0.1,\n",
    "                  callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
